{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3iKGMs5OWO3abio3r8n7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eloyhernandezlua/MentalHealthProjectAI/blob/main/ASR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlKerh7RsT6A"
      },
      "source": [
        "!pip install speechbrain\n",
        "!pip install transformers\n",
        "!pip install pydub\n",
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGlEeDIKsjLw"
      },
      "source": [
        "import time\n",
        "from time import perf_counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from google.colab import files\n",
        "import moviepy.editor\n",
        "from transformers import pipeline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39f9lnusn3_"
      },
      "source": [
        "from speechbrain.pretrained import EncoderDecoderASR\n",
        "\n",
        "asr_model2 = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"pretrained_models/asr-crdnn-rnnlm-librispeech\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTDCkVM_suJe"
      },
      "source": [
        "def transcribe_audio(fileList = []):\n",
        "  listOfText = []\n",
        "  if fileList == [] :\n",
        "    uploaded = files.upload()\n",
        "    listOfAudios = list(uploaded.keys())\n",
        "  else:\n",
        "    listOfAudios = fileList\n",
        "  \n",
        "  a = perf_counter()\n",
        "  for file in listOfAudios:\n",
        "    duration = librosa.get_duration(filename=file)\n",
        "    t1 = 0\n",
        "    t2 = duration * 1000 if duration < 30 else 30000\n",
        "    textTemp = \"\"\n",
        "    j = 1\n",
        "    i = 1\n",
        "    final_fragment = False\n",
        "    while t2 <= duration*1000 and not final_fragment:\n",
        "      final_fragment = True if t2 == duration * 1000 else False\n",
        "      newAudio = AudioSegment.from_wav(file)\n",
        "      newAudio = newAudio[t1:t2]\n",
        "      name = 'Audio_' + str(j) + '_segment_' + str(i) + '.wav'\n",
        "      newAudio.export(name, format=\"wav\")\n",
        "      t1 += 30000\n",
        "      t2 = duration * 1000 if t2 + 30000 > duration * 1000 else t2 + 30000\n",
        "      i+= 1\n",
        "      print(\"\\nAnalizando: \" + name)\n",
        "      resAux = asr_model2.transcribe_file(os.getcwd() + \"/\" + name)\n",
        "      textTemp = textTemp + \" \" + resAux\n",
        "    \n",
        "    listOfText.append(textTemp[1:])\n",
        "    j += 1\n",
        "  print(\"\\nTerminado en: \" + str(f'{perf_counter() - a:.2f}') + \" seg.\\n\")\n",
        "\n",
        "  return listOfText\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KItMFin3sxQt"
      },
      "source": [
        "def transcribe_video(fileList = []):\n",
        "  listOfText = []\n",
        "  if fileList == [] :\n",
        "    uploaded = files.upload()\n",
        "    listOfAudios = list(uploaded.keys())\n",
        "  else:\n",
        "    listOfAudios = fileList\n",
        "  a = perf_counter()\n",
        "  for file in listOfAudios:\n",
        "    duration = librosa.get_duration(filename=file)\n",
        "    j = 1\n",
        "    i = 1\n",
        "    video = moviepy.editor.VideoFileClip(os.getcwd() + \"/\" + file)\n",
        "    audio = video.audio\n",
        "    nameVideo = \"AudioExtraction_Video_\" + str(j) + (\".wav\")\n",
        "    print(\"\\nExporting audio from video: \" + file + \"\\nTo: \" + nameVideo)\n",
        "    audio.write_audiofile(os.getcwd() + \"/\" + nameVideo)\n",
        "    t1 = 0\n",
        "    t2 = duration * 1000 if duration < 30 else 30000\n",
        "    textTemp = \"\"\n",
        "    \n",
        "    final_fragment = False\n",
        "    while t2 <= duration*1000 and not final_fragment:\n",
        "      final_fragment = True if t2 == duration * 1000 else False\n",
        "      newAudio = AudioSegment.from_wav(nameVideo)\n",
        "      newAudio = newAudio[t1:t2]\n",
        "      name = 'Video_' + str(j) + '_segment_' + str(i) + '.wav'\n",
        "      newAudio.export(name, format=\"wav\")\n",
        "      t1 += 30000\n",
        "      t2 = duration * 1000 if t2 + 30000 > duration * 1000 else t2 + 30000\n",
        "      i+= 1\n",
        "      print(\"\\nAnalizando: \" + name)\n",
        "      resAux = asr_model2.transcribe_file(os.getcwd() + \"/\" + name)\n",
        "      textTemp = textTemp + \" \" + resAux\n",
        "    \n",
        "    listOfText.append(textTemp[1:])\n",
        "    j += 1\n",
        "  print(\"\\nTerminado en: \" + str(f'{perf_counter() - a:.2f}') + \" seg.\\n\")\n",
        "\n",
        "  return listOfText"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}